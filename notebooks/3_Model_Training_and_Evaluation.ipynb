{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8133c3-4d26-4dbf-9403-38296ae32bfc",
   "metadata": {},
   "source": [
    "### Step 3: Model Training and Evaluation\n",
    "\n",
    "We applied Logistic Regression, Random Forest, and Support Vector Machine models to classify between normal and cancerous samples. The dataset was split into 70% training and 30% testing. Accuracy, precision, recall, and F1-score were used to assess model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8fbd86-8c17-443f-94bf-1fc563a22bb3",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "This notebook builds ML models and evaluates performance.\n",
    "\n",
    "## Steps involved in Model Training and Evaluation.  \n",
    "\n",
    "\n",
    "##  Data Loading  \n",
    "**Load the merged and labeled dataset containing cfDNA methylation and miRNA features.**\n",
    "\n",
    "\n",
    "\n",
    "##  Data Standardization  \n",
    "**Standardize all feature values using Z-score normalization to ensure uniform scale for ML algorithms.**\n",
    "\n",
    "\n",
    "\n",
    "## Train-Test Split  \n",
    "**Split the dataset into 80% training and 20% testing sets using stratified sampling to preserve class distribution.**\n",
    "\n",
    "\n",
    "\n",
    "## Feature Selection  \n",
    "**Use ANOVA F-score to select the top 100 most relevant features contributing to classification.**\n",
    "\n",
    "\n",
    "\n",
    "## Model Training – Logistic Regression  \n",
    "**Train a Logistic Regression model using the selected features to classify tumor vs normal samples.**\n",
    "\n",
    "\n",
    "\n",
    "##  Model Training – Random Forest  \n",
    "**Train a Random Forest model as a robust ensemble classifier for comparison and improved accuracy.**\n",
    "\n",
    "\n",
    "\n",
    "##  Evaluation  \n",
    "**Evaluate model performance using confusion matrix, precision, recall, F1-score, and accuracy metrics.**\n",
    "\n",
    "\n",
    "\n",
    "##  Save Outputs  \n",
    "**Export selected feature list and model performance reports for documentation and future reference.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb790e-fc8a-455e-b933-a18fcb094a97",
   "metadata": {},
   "source": [
    "###  Load Prepared Dataset for Modeling\n",
    "\n",
    "In this step, we load the final, labeled, and lightweight version of the dataset that was previously created by merging miRNA and methylation features. This dataset will now be used for training and evaluating machine learning models. We also preview the shape and structure to ensure it has loaded correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292ef77f-74c7-4009-9177-c47a1a913946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset loaded successfully.\n",
      " Shape of dataset: (450, 1001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa-let-7a-1</th>\n",
       "      <th>hsa-let-7a-2</th>\n",
       "      <th>hsa-let-7a-3</th>\n",
       "      <th>hsa-let-7b</th>\n",
       "      <th>hsa-let-7c</th>\n",
       "      <th>hsa-let-7d</th>\n",
       "      <th>hsa-let-7e</th>\n",
       "      <th>hsa-let-7f-1</th>\n",
       "      <th>hsa-let-7f-2</th>\n",
       "      <th>hsa-let-7g</th>\n",
       "      <th>...</th>\n",
       "      <th>NUP107_cg00036115</th>\n",
       "      <th>A2BP1_cg00036119</th>\n",
       "      <th>GALP_cg00036137</th>\n",
       "      <th>ADCY9_cg00036258</th>\n",
       "      <th>KIF26B_cg00036263</th>\n",
       "      <th>GRIN2A_cg00036299</th>\n",
       "      <th>ARL6IP4_cg00036328</th>\n",
       "      <th>ATXN7_cg00036369</th>\n",
       "      <th>MOGS_cg00036386</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA.05.4384</th>\n",
       "      <td>13.8766</td>\n",
       "      <td>14.8745</td>\n",
       "      <td>13.8822</td>\n",
       "      <td>13.8259</td>\n",
       "      <td>10.6177</td>\n",
       "      <td>8.7119</td>\n",
       "      <td>10.8698</td>\n",
       "      <td>5.3122</td>\n",
       "      <td>15.1357</td>\n",
       "      <td>10.3183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3378</td>\n",
       "      <td>-0.2096</td>\n",
       "      <td>0.2053</td>\n",
       "      <td>0.3476</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>-0.1074</td>\n",
       "      <td>-0.4301</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>-0.4720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.05.4390</th>\n",
       "      <td>11.7425</td>\n",
       "      <td>12.7576</td>\n",
       "      <td>11.7578</td>\n",
       "      <td>13.0601</td>\n",
       "      <td>7.6080</td>\n",
       "      <td>8.6168</td>\n",
       "      <td>10.4833</td>\n",
       "      <td>3.4069</td>\n",
       "      <td>12.4367</td>\n",
       "      <td>9.3119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3536</td>\n",
       "      <td>-0.2863</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>-0.0471</td>\n",
       "      <td>-0.4155</td>\n",
       "      <td>0.3944</td>\n",
       "      <td>-0.4646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.05.4396</th>\n",
       "      <td>14.0194</td>\n",
       "      <td>15.0255</td>\n",
       "      <td>14.0367</td>\n",
       "      <td>14.5902</td>\n",
       "      <td>11.1171</td>\n",
       "      <td>9.8454</td>\n",
       "      <td>11.4738</td>\n",
       "      <td>4.3995</td>\n",
       "      <td>14.3723</td>\n",
       "      <td>9.7934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2830</td>\n",
       "      <td>-0.2535</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>0.4603</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>-0.4004</td>\n",
       "      <td>0.3917</td>\n",
       "      <td>-0.4539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.05.4405</th>\n",
       "      <td>12.9428</td>\n",
       "      <td>13.9327</td>\n",
       "      <td>12.9499</td>\n",
       "      <td>14.2170</td>\n",
       "      <td>11.1093</td>\n",
       "      <td>8.4836</td>\n",
       "      <td>10.3909</td>\n",
       "      <td>3.1985</td>\n",
       "      <td>12.5092</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3241</td>\n",
       "      <td>-0.1369</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.3384</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>-0.0564</td>\n",
       "      <td>-0.4108</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>-0.4704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.05.4410</th>\n",
       "      <td>12.7150</td>\n",
       "      <td>13.7157</td>\n",
       "      <td>12.7252</td>\n",
       "      <td>13.7465</td>\n",
       "      <td>10.3613</td>\n",
       "      <td>8.7360</td>\n",
       "      <td>10.0696</td>\n",
       "      <td>3.9421</td>\n",
       "      <td>13.0051</td>\n",
       "      <td>9.0249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3825</td>\n",
       "      <td>-0.1144</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.4682</td>\n",
       "      <td>-0.0941</td>\n",
       "      <td>-0.4134</td>\n",
       "      <td>0.4214</td>\n",
       "      <td>-0.4599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              hsa-let-7a-1  hsa-let-7a-2  hsa-let-7a-3  hsa-let-7b  \\\n",
       "TCGA.05.4384       13.8766       14.8745       13.8822     13.8259   \n",
       "TCGA.05.4390       11.7425       12.7576       11.7578     13.0601   \n",
       "TCGA.05.4396       14.0194       15.0255       14.0367     14.5902   \n",
       "TCGA.05.4405       12.9428       13.9327       12.9499     14.2170   \n",
       "TCGA.05.4410       12.7150       13.7157       12.7252     13.7465   \n",
       "\n",
       "              hsa-let-7c  hsa-let-7d  hsa-let-7e  hsa-let-7f-1  hsa-let-7f-2  \\\n",
       "TCGA.05.4384     10.6177      8.7119     10.8698        5.3122       15.1357   \n",
       "TCGA.05.4390      7.6080      8.6168     10.4833        3.4069       12.4367   \n",
       "TCGA.05.4396     11.1171      9.8454     11.4738        4.3995       14.3723   \n",
       "TCGA.05.4405     11.1093      8.4836     10.3909        3.1985       12.5092   \n",
       "TCGA.05.4410     10.3613      8.7360     10.0696        3.9421       13.0051   \n",
       "\n",
       "              hsa-let-7g  ...  NUP107_cg00036115  A2BP1_cg00036119  \\\n",
       "TCGA.05.4384     10.3183  ...            -0.3378           -0.2096   \n",
       "TCGA.05.4390      9.3119  ...            -0.3536           -0.2863   \n",
       "TCGA.05.4396      9.7934  ...            -0.2830           -0.2535   \n",
       "TCGA.05.4405      8.4956  ...            -0.3241           -0.1369   \n",
       "TCGA.05.4410      9.0249  ...            -0.3825           -0.1144   \n",
       "\n",
       "              GALP_cg00036137  ADCY9_cg00036258  KIF26B_cg00036263  \\\n",
       "TCGA.05.4384           0.2053            0.3476             0.4723   \n",
       "TCGA.05.4390           0.2775            0.3677             0.4791   \n",
       "TCGA.05.4396           0.3093            0.3364             0.4603   \n",
       "TCGA.05.4405           0.2914            0.3384             0.4605   \n",
       "TCGA.05.4410           0.2545            0.3771             0.4682   \n",
       "\n",
       "              GRIN2A_cg00036299  ARL6IP4_cg00036328  ATXN7_cg00036369  \\\n",
       "TCGA.05.4384            -0.1074             -0.4301            0.3398   \n",
       "TCGA.05.4390            -0.0471             -0.4155            0.3944   \n",
       "TCGA.05.4396             0.0100             -0.4004            0.3917   \n",
       "TCGA.05.4405            -0.0564             -0.4108            0.3659   \n",
       "TCGA.05.4410            -0.0941             -0.4134            0.4214   \n",
       "\n",
       "              MOGS_cg00036386  Label  \n",
       "TCGA.05.4384          -0.4720      0  \n",
       "TCGA.05.4390          -0.4646      0  \n",
       "TCGA.05.4396          -0.4539      0  \n",
       "TCGA.05.4405          -0.4704      0  \n",
       "TCGA.05.4410          -0.4599      0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the lightweight merged dataset\n",
    "df = pd.read_csv(r\"C:/Users/sanja/cfDNA_LungCancer_ML/data/processed/merged_labeled_light.csv\", index_col=0)\n",
    "\n",
    "print(\" Dataset loaded successfully.\")\n",
    "print(\" Shape of dataset:\", df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47363c-334d-4aba-9d31-4ef2c90b7fa3",
   "metadata": {},
   "source": [
    "###  Split Features and Labels, Standardize, and Prepare for Training\n",
    "\n",
    "In this section, we separate the features (X) and labels (y) from the merged dataset. To ensure uniform scaling across features, we apply standardization using `StandardScaler`. Then, we split the dataset into training and testing sets (80% train, 20% test) while maintaining class distribution using stratified sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eeec009-eb02-405d-bc9e-aa3b4e7b21bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data split and scaled successfully.\n",
      " X_train: (360, 1000)\n",
      " X_test : (90, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Split into features and labels\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\" Data split and scaled successfully.\")\n",
    "print(\" X_train:\", X_train.shape)\n",
    "print(\" X_test :\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec6a47-aa5a-4899-b5b6-203c16aca675",
   "metadata": {},
   "source": [
    "###  Handling Missing and Infinite Values for Model Readiness\n",
    "\n",
    "Before training models, it's critical to ensure data quality. This code checks for any missing (NaN) or infinite (Inf) values in the training set. If such issues exist, we clean the dataset using `dropna()`, restandardize the features, and perform a fresh train-test split. This ensures the input to machine learning models is clean, consistent, and free of anomalies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd33751a-a8b3-410f-897d-017a7b64a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Any NaNs in X_train? True\n",
      "Any NaNs in y_train? False\n",
      " Any Infs in X_train? False\n",
      " Shapes - X_train: (360, 1000)  y_train: (360,)\n",
      " Cleaned and ready. X_train shape: (336, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(\" Any NaNs in X_train?\", np.isnan(X_train).any())\n",
    "print(\"Any NaNs in y_train?\", np.isnan(y_train).any())\n",
    "\n",
    "print(\" Any Infs in X_train?\", np.isinf(X_train).any())\n",
    "print(\" Shapes - X_train:\", X_train.shape, \" y_train:\", y_train.shape)\n",
    "# Re-do train-test split with dropna\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Separate features and labels again\n",
    "X = df_cleaned.drop(columns=['Label'])\n",
    "y = df_cleaned['Label']\n",
    "\n",
    "# Scale again\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split again\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\" Cleaned and ready. X_train shape:\", X_train.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606e0c5-f88a-44a3-a391-e1ee1870cf4b",
   "metadata": {},
   "source": [
    "###  Logistic Regression Model Training and Evaluation\n",
    "\n",
    "This section fits a Logistic Regression model on the training data and evaluates its performance on the test set. The classification report provides key metrics like precision, recall, F1-score, and support, helping assess how well the model distinguishes between normal and cancer samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9398bc3d-820f-48a6-9498-5c53d7bb5da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58        42\n",
      "           1       0.60      0.71      0.65        42\n",
      "\n",
      "    accuracy                           0.62        84\n",
      "   macro avg       0.62      0.62      0.62        84\n",
      "weighted avg       0.62      0.62      0.62        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\" Logistic Regression Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8f7aa-b319-4000-9233-aca292a6c11f",
   "metadata": {},
   "source": [
    "###  Random Forest Model Training and Evaluation\n",
    "\n",
    "In this step, we train a Random Forest classifier with 100 decision trees to capture complex patterns in the data. After training, the model's performance on the test set is evaluated using a classification report, offering insights into its ability to classify lung cancer and normal cases accurately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058e7700-1959-442c-a6ce-09d8344fdcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60        42\n",
      "           1       0.60      0.62      0.61        42\n",
      "\n",
      "    accuracy                           0.61        84\n",
      "   macro avg       0.61      0.61      0.61        84\n",
      "weighted avg       0.61      0.61      0.61        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\" Random Forest Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92504774-6311-45f6-921d-07f103c3237d",
   "metadata": {},
   "source": [
    "###  Support Vector Machine (SVM) Model Training and Evaluation\n",
    "\n",
    "We use a Support Vector Machine with an RBF (Radial Basis Function) kernel to handle non-linear relationships in the data. This model is trained on the standardized training set, and its classification performance is assessed using precision, recall, and F1-score metrics on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10660ed8-d9f3-47e3-abb4-0523ae7ff5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        42\n",
      "           1       0.62      0.71      0.67        42\n",
      "\n",
      "    accuracy                           0.64        84\n",
      "   macro avg       0.65      0.64      0.64        84\n",
      "weighted avg       0.65      0.64      0.64        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "print(\" SVM Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282039e-e8e8-4658-b135-4be612a33f6d",
   "metadata": {},
   "source": [
    "###  Model Accuracy Comparison\n",
    "\n",
    "After evaluating all three models—Logistic Regression, Random Forest, and Support Vector Machine (SVM)—we compare their classification accuracies side-by-side. This provides a quick overview of each model's ability to correctly predict cancer status from the integrated cfDNA methylation and miRNA features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13708988-d9d1-482b-b59f-759c135f09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy Comparison:\n",
      "Logistic Regression: 0.6190\n",
      "Random Forest      : 0.6071\n",
      "SVM                : 0.6429\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracy Comparison:\")\n",
    "print(f\"Logistic Regression: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Random Forest      : {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"SVM                : {accuracy_score(y_test, y_pred_svm):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
